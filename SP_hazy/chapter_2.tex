%   Filename    : chapter_2.tex 
\chapter{Review of Related Literature}
\label{sec:relatedlit}

This chapter discusses the features, capabilities, and limitations of existing research, algorithms, or software  that are related/similar to Hazy. Hazy, as an application, identfies the vehicles passing across the camera feed and calculates their CO2 emssion average


\begin{comment}
%
% IPR acknowledgement: the contents withis this comment are from Ethel Ong's slides on RRL.
%
Guide on Writing your RRL chapter
 
1. Identify the keywords with respect to your research
      One keyword = One document section
                Examples: 2.1 Story Generation Systems
			 2.2 Knowledge Representation

2.  Find references using these keywords

3.  For each of the references that you find,
        Check: Is it relevant to your research?
        Use their references to find more relevant works.

4. Identify a set of criteria for comparison.
       It will serve as a guide to help you focus on what to look for

5. Write a summary focusing on -
       What: A short description of the work
       How: A summary of the approach it utilized
       Findings: If applicable, provide the results
        Why: Relevance to your work

6. At the end of each section,  show a Table of Comparison of the related works 
   and your proposed project/system

\end{comment}

\section{Air Quality Monitoring Systems}
Air quality monitoring systems are systems that collects data to record and or or analyze atmospheric emission levels. There are various systems for air quality monitoring. \cite{zoogman_2017} showcased in a journal the use of satellite imagery for large-scale air quality monitoring. They call this instrument TEMPO (Tropospheric Emissions: Monitoring of Pollution). It is an instrument that collects data on tropospheric emissions such as NO2, SO2, H2CO, Methane, etc from a satellite in a geostationary orbit. This system is wide-range and precise,  however, access to the equipment is limited.  A more accessible air monitoring system was made by \cite{zheng_2016} using several sensors. This system makes use of LPWA (low power wide area) to give it a wider coverage compared to the IoT (Internet-of-Things ) and the air quality data can be accessed through a mobile application. These systems make use of dedicated sensors to collect emission data whereas this project will make use of computer vision and machine learning.


\section{Air Pollution from Vehicles}
The Philippines currently has a problem with air pollution. According to \cite{TANTENGCO2022}, the Philippines’ PM2·5 concentrations in urban areas exceed the WHO guideline value. They further state that the Philippines’ PM2·5 levels reaches 58·4 ug/m3 in traffic sites of Metro Manila during the dry season. Though there could be different sources of air pollution, 65 percent of the air pollutants come from mobile sources such as: cars, motorcycles, trucks, and buses \cite{EMB_2015}.

	Furthermore, CO2, a component of greenhouse gasses, totaled  to “30 million tons and 56 thousand tons of particulate matter” \cite{FabianGota2009} in the Philippines and the transport sector contributed to 38 percent of fuel combustion back in 2000. The authors have noted that the motorized vehicle count would double by 2020. The increase of motorized vehicles also means an increase in its air pollution contribution. 

A study by \cite{lu_2022} analyzes the emissions of vehicles due to its impact on air pollution and road-environmental safety. The results show that in 2018 to 2019, two hundred eighty-two vehicle emission standard violations were recorded by the Land Transportation Organization (LTO) office. All of these violations were due to smoke-belching from vehicles. Another result to note was that all the violations were during work hours (6:00 AM to 5:00 PM). The vehicles caught for dangerous emissions were more than 10 years old, with one-third between 10 to 19 years old. The paper concluded that not only ensuring safe vehicle emissions can play an important role in reducing air pollution, there is a need for implementation and monitoring of said vehicle emissions to be within a safer threshold. The researcher notes that the Philippines still needs improvement in addressing the concerns of vehicles contributing to air pollution.


\section{Vehicle Detection and Tracking}

	Vehicle detection is a method of identifying a vehicle via a camera. Research on this method started being conducted during the late 1970s \cite{NathDeb2012} and as more vehicles enter our roads, there has also been more interest in the topic.  \cite{Meng_2020} defines vehicle detection based computer vision as aiming at identifying and locating vehicles by digital images or videos. They further simplify the idea by stating that vehicle detection detects “blocks”, which reflects the vehicle’s position from the images and videos.

	A paper by \cite{yang_2020} proposed an “object tracker–detector combined with an object tracking algorithm” for tracking vehicles in traffic. They created the tracker by combining strategies for the You Only Look Once (YOLO) model (which will be talked about in 2.4) with a correlation filter (CF) tracker. To elaborate on the object detection, a detection box merge strategy was used for YOLO. This is to prevent the algorithm from partially detecting an object or detecting it more than once. For the tracker, a “deep feature-based CF tracker” was designed. Lastly, to combine both into a tracker-detection program, a tracker was “first used to predict location of an object in the subsequent frame.”

	Another process to detect and track the vehicle would be through background subtraction. Background subtraction, according to Huang BJ. et al. \citeyear{Huang_2017}, is used to extract the moving objects and then filter the unwanted images through image processing tools. 
	
	A recent study by Li et al. \citeyear{li_2022} studies another method of vehicle detection and recognition – via Infrared Image and Feature Extraction. The paper states that due to infrared images having shortcomings such as poor contrast or blurred edges, they mainly studied the color space preprocessing of the image with the use of threshold segmentation method and infrared image enhancement to separate the vehicle and the background. Techniques such as the Median filter and the Improved Histogram Equalization are then used to remove the noise from the infrared image and to enhance the contrast of the image, respectively. Vertical Sobel operator is then selected to enhance the vertical edge of the image. Vertical Sobel operator is used to enhance the vertical edge of the image. Lastly, vertical edge symmetry, aspect ratio, and gray-scale symmetry are utilized for the vehicle detection and recognition.


\subsection { Vehicle Make and Model Recognition}

	Vehicle tracking can be used for identifying the information of the vehicle, such as its brand and model. A recent paper by Saravi and Edirisinghe \citeyear{Saravi2017} presents a Vehicle Make and Model Recognition (VMMR) System that accepts a video feed and returns the make and model of the vehicles detected on the feed. This system tracks the vehicle’s license plate followed by selecting the region of interest above the plate–the vehicle. As the vehicle moves along the camera, its license plate is also detected across multiple frames while motion segmentation was used to keep track of the static area above the license plate.

	The previously mentioned system is one of the most recent VMMR systems to be produced. Other applications of the same purpose before it, would have had to be checked for its accuracy for the system to be viable. A paper done by Hassan et al. \citeyear{Hassan2021} identifies 196 different types of vehicles based on make, model, and year using Stanford Cars and VMMRbd-51. This was to evaluate multiple deep learning architectures for vehicle image classification. Techniques such as transfer learning were employed to reduce training time and improve performance. Then, they used different augmentation methods to the training dataset to increase the number of images. Lastly, k-fold cross-validation was used and resulted in an accuracy of 93.96\% .




\section{A case for YOLOv5}
	Yolov5 is a pretrained algorithm that uses a system of grids to detects objects from images or videos (https://docs.ultralytics.com/). This tool will be used for the vehicle detection in this project. 

\subsection{Application of YOLOv5}
One application of this algorithm was done by Yan et al. \citeyear{yan_2021} for an apply picking robot. YOLOv5 was used to identify apples, however the algorithm cannot detect apples that are safe to pick and those that are not. This may cause the picking arm of the robot to break if it tries to grasp an apple that is occluded by a solid object. They solved this problem by improving on the modules used for the algorithm. This is not a problem for this project as it only counts the number of vehicles without interacting with them. 

In a study done by Zhou et al. \citeyear{zhou_2021}, they applied YOLOv5 algorithm to detect safety helmets on workers. The algorithm had an average detection speed of 110 fps in real-time. With a 94.7\% effectiveness (The model was trained and tested  using 6045 data sets) the algorithm proved to be viable for real-time detection.

\subsection{Advantages of YOLOv5}
	YOLOv5 is one of the commonly used algorithm for object detection. It is faster that other object detection algorithms like Region-based Convolutional Neural Networks (RCNN), Fast RCNN, and Faster RCNN. Gandhi \citeyear{gandhi_2018} wrote in an article the comparism between the RCNN algorithms and YOLOv5. He said that the major drawbacks of RCNN is that it classifies 2000 regions per image everytime it runs, it cannot run in realtime and it is a fixed algorithm. Fast RCNN employs a similar algorithm to RCNN but instead of classifying regions everytime, it uses CNN to generate a convolutional feature map where the bounding regions are derived. Faster RCNN improves upon this by using a different network for predicting the regions of proposal. In his comparison he found that Fast RCNN improves on the speed of RCNN significantly. He also mentioned that Faster RCNN, the fastest of the RCNN algorithms, is viable for realtime object detection. 

\section{Vehicle Recognition/Identification Applications}
	
	In this study, Vehicle Recognition or Identification Applications would be considered as applications that either use any form of video-based software in locating the vehicle on the display feed, or software where static images can be used in identification. Chintalacheruvu and Muthukumar \citeyear{chintalacheruvu_2012} state that video based vehicle detection technology has features such as: “non-intrusiveness and comprehensive vehicle behavior data collection capabilities”, that it has become an integral part of f Intelligent Transportation System (ITS)

	V-App Vehicle Detection is a real-time vehicle detection system that utilizes the visual analytics provided by Meraki Smart Cameras and a License Plate Recognition function to ‘overcome the limitations of common sensors’. It also has features such as: vehicle distribution, which detects transit vehicles in an area by grouping them into categories; vehicle count and directions, which gets info on the total amount of vehicles transited and their direction details; and average busiest hours, which shows the higher transit and occupancy peaks in a graph. \cite{VAPP_ND}

	BitRefine Heads is a computer vision platform that “utilizes deep learning algorithms to perform high-level visual analysis” . It is a platform that detects everyday objects from any angle and also has a vehicle detection system. The recognition module is pre-trained and can detect vehicles as well as recognize the car’s model based on the visual features. It gets its video source from an Real Time Streaming Protocol (RTSP) stream from an IP-camera. The video then goes to a neural classifier that locates the vehicle in the frame and identifies its class using their own vehicle recognition module’s database.  The tracking module then takes the results and builds the vehicle’s movement track. Then it passes additional images of said vehicle to the neural module to check whether the class is correct. \cite{BITREFINE_ND}


\section{Vehicle Emission Calculator Applications}
	In this study, a vehicle emission calculator application would be regarded as applications that provide the total emission count or estimate of a vehicle after given inputs such as: a car’s make and model, car type, fuel type, and the like.

	The Myclimate Car calculator is an online web browser application that determines the CO2 emissions of a car during its travel. The application asks for the distance traveled, along with the fuel type and fuel consumption. Users also have the option to enter the cart type (compact, mid-range, luxury/SUV/Van) to add to the calculation of the CO2 amount.  The basis of this calculation is through the utilization of the ecoinvent database (Version 3.6), using the IPCC 2013  (Intergovernmental Panel on Climate Change) evaluation method. The emissions are calculated per vehicle kilometer (vkm). The application creators further note that there is an uncertainty margin of 5\% added to the emissions due to statistical values used in the calculations. \cite{MCF_ND}

	The Next Greencar Make/Model Search Tool is an online car make and model search tool by Nextgreencar.com, a website established in 2007 in the purpose of helping car buyers transition from “fossil cars” to electric cars. This search tool takes the input of a car’s manufacturer and/or a specific model to provide results of : tail-pipe CO2, NOx, particulate emissions and the NGC Rating. NGC Rating or Next Green Car Rating is a rating developed by the company to assess the environmental impact. \cite{Lilly_ND}  The site then lists all the cars that satisfy the query, allowing users to compare them between their emissions. 

	The CO2 emission functionality of the mentioned applications would resemble that of the one in Hazy, through the use of a database to train the software of the different makes and models of cars along with their CO2 emissions via the dataset taken from Kaggle. The difference with Hazy and the related applications is that instead of relying on user input to get the vehicle’s CO2 emission, it relies on the information passed from the vehicle recognition to supply it with the make and model of the car.

\section{Summary}
 As the usage of vehicles in the Philippines rapidly increases through the years, it also starts becoming the main contributor to the air pollution in the country – a problem which the Philippines is still trying to mitigate. The studies mentioned above mention that in an attempt to solve this concern, emissions such as Carbon Dioxide from vehicles are collected and analyzed through making applications that can keep track of the emissions by identifying a car’s make and model.

	A car’s make and model can be identified through a database and this can be utilized to create a system to identify cars via either still images and video. This chapter presented studies from different researchers that produced vehicle make and model identification and recognition systems through machine learning and computer vision. Some of the applications used as an example can identify objects from a live video feed and produce results that list the vehicle’s make and model. Most of the related applications for vehicle tracking all use an in-house system that are  not publicly available to use without having to pay for them. The researchers instead found YOLOv5, an open source pre-trained algorithm that uses a system of grids to detect objects from images or videos to be used in the study.

	The recent studies make note of the interest in vehicle tracking systems and its benefits in managing traffic. This information, combined with the goal of reducing the emissions from vehicles that contribute to pollution, can be used to support the researchers’ purposes of the study.



