%   Filename    : chapter_2.tex 
\chapter{Review of Related Literature}
\label{sec:relatedlit}

This chapter discusses the features, capabilities, and limitations of existing research, algorithms, or software  that are related/similar to Hazy. Hazy, as an application, identfies the vehicles passing across the camera feed and calculates their CO2 emssion average


\begin{comment}
%
% IPR acknowledgement: the contents withis this comment are from Ethel Ong's slides on RRL.
%
Guide on Writing your RRL chapter
 
1. Identify the keywords with respect to your research
      One keyword = One document section
                Examples: 2.1 Story Generation Systems
			 2.2 Knowledge Representation

2.  Find references using these keywords

3.  For each of the references that you find,
        Check: Is it relevant to your research?
        Use their references to find more relevant works.

4. Identify a set of criteria for comparison.
       It will serve as a guide to help you focus on what to look for

5. Write a summary focusing on -
       What: A short description of the work
       How: A summary of the approach it utilized
       Findings: If applicable, provide the results
        Why: Relevance to your work

6. At the end of each section,  show a Table of Comparison of the related works 
   and your proposed project/system

\end{comment}

\section{Air Quality Monitoring Systems}
Air quality monitoring systems are systems that collects data to record and or or analyze atmospheric emission levels. There are various systems for air quality monitoring. \cite{zoogman_2017} showcased in a journal the use of satellite imagery for large-scale air quality monitoring. They call this instrument TEMPO (Tropospheric Emissions: Monitoring of Pollution). It is an instrument that collects data on tropospheric emissions such as \ch{NO2}, \ch{SO2}, \ch{H2CO}, Methane, etc from a satellite in a geostationary orbit. This system is wide-range and precise,  however, access to the equipment is limited.  A more accessible air monitoring system was made by \cite{zheng_2016} using several sensors. This system makes use of low-power wide-area network (LPWAN) to give it a wider coverage compared to the IoT (Internet-of-Things ) and the air quality data can be accessed through a mobile application. These systems make use of dedicated sensors to collect emission data whereas this project will make use of computer vision and machine learning.


\section{Air Pollution from Vehicles}
The Philippines currently has a problem with air pollution. According to \cite{TANTENGCO2022}, the Philippines’ PM2·5 concentrations in urban areas exceed the WHO guideline value. They further state that the Philippines’ PM2·5 levels reaches 58·4 ug/m3 in traffic sites of Metro Manila during the dry season. Though there could be different sources of air pollution, 65 percent of the air pollutants come from mobile sources such as: cars, motorcycles, trucks, and buses \cite{EMB_2015}.

	Furthermore, CO2, a component of greenhouse gasses, totaled  to “30 million tons and 56 thousand tons of particulate matter” \cite{FabianGota2009} in the Philippines and the transport sector contributed to 38 percent of fuel combustion back in 2000. The authors have noted that the motorized vehicle count would double by 2020. The increase of motorized vehicles also means an increase in its air pollution contribution. 

A study by \cite{lu_2022} analyzes the emissions of vehicles due to its impact on air pollution and road-environmental safety. The results show that in 2018 to 2019, two hundred eighty-two vehicle emission standard violations were recorded by the Land Transportation Organization (LTO) office. All of these violations were due to smoke-belching from vehicles. Another result to note was that all the violations were during work hours (6:00 AM to 5:00 PM). The vehicles caught for dangerous emissions were more than 10 years old, with one-third between 10 to 19 years old. The paper concluded that not only ensuring safe vehicle emissions can play an important role in reducing air pollution, there is a need for implementation and monitoring of said vehicle emissions to be within a safer threshold. The researcher notes that the Philippines still needs improvement in addressing the concerns of vehicles contributing to air pollution.

A recent paper by \citeA{rito_lopez_biona_2021} raises the concern of quantifying traffic flow, which in this context, is also used for calculating the emission and energy consumption factors. The researchers state that calculating traffic flow has other researchers “deal with complex and arduous tasks, especially when conducting actual surveys”. In this paper, the researchers instead utilized crowdsourced data from Google Maps to estimate mobile emissions and energy use from the traffic flow of the road. The method was used on the EDSA highway in the Philippines, and managed to garner a 8.63\% error with respect to the total vehicle count.

\section{Vehicle Detection and Tracking}

	Vehicle detection is a method of identifying a vehicle via a camera. Research on this method started being conducted during the late 1970s \cite{NathDeb2012} and as more vehicles enter our roads, there has also been more interest in the topic. \cite{Meng_2020} defines vehicle detection based computer vision as aiming at identifying and locating vehicles by digital images or videos. They further simplify the idea by stating that vehicle detection detects “blocks”, which reflects the vehicle’s position from the images and videos.

	A paper by \cite{yang_2020} proposed an “object tracker–detector combined with an object tracking algorithm” for tracking vehicles in traffic. They created the tracker by combining strategies for the You Only Look Once (YOLO) model (which will be talked about in 2.4) with a correlation filter (CF) tracker. To elaborate on the object detection, a detection box merge strategy was used for YOLO. This is to prevent the algorithm from partially detecting an object or detecting it more than once. For the tracker, a “deep feature-based CF tracker” was designed. Lastly, to combine both into a tracker-detection program, a tracker was “first used to predict location of an object in the subsequent frame.”

	Another process to detect and track the vehicle would be through background subtraction. Background subtraction, according to Huang BJ. et al. \citeyear{Huang_2017}, is used to extract the moving objects and then filter the unwanted images through image processing tools. 
	
	A recent study by Li et al. \citeyear{li_2022} studies another method of vehicle detection and recognition – via Infrared Image and Feature Extraction. The paper states that due to infrared images having shortcomings such as poor contrast or blurred edges, they mainly studied the color space preprocessing of the image with the use of threshold segmentation method and infrared image enhancement to separate the vehicle and the background. Techniques such as the Median filter and the Improved Histogram Equalization are then used to remove the noise from the infrared image and to enhance the contrast of the image, respectively. Vertical Sobel operator is then selected to enhance the vertical edge of the image. Vertical Sobel operator is used to enhance the vertical edge of the image. Lastly, vertical edge symmetry, aspect ratio, and gray-scale symmetry are utilized for the vehicle detection and recognition.


\section{A case for YOLOv5}
	Yolov5 is a pretrained algorithm that uses a system of grids to detects objects from images or videos (https://docs.ultralytics.com/). This tool will be used for the vehicle detection in this project. 

\subsection{Application of YOLOv5}
One application of this algorithm was done by Yan et al. \citeyear{yan_2021} for an apply picking robot. YOLOv5 was used to identify apples, however the algorithm cannot detect apples that are safe to pick and those that are not. This may cause the picking arm of the robot to break if it tries to grasp an apple that is occluded by a solid object. They solved this problem by improving on the modules used for the algorithm. This is not a problem for this project as it only counts the number of vehicles without interacting with them. 

In a study done by Zhou et al. \citeyear{zhou_2021}, they applied YOLOv5 algorithm to detect safety helmets on workers. The algorithm had an average detection speed of 110 fps in real-time. With a 94.7\% effectiveness (The model was trained and tested  using 6045 data sets) the algorithm proved to be viable for real-time detection.

\subsection{Advantages of YOLOv5}
	YOLOv5 is one of the commonly used algorithm for object detection. It is faster that other object detection algorithms like Region-based Convolutional Neural Networks (RCNN), Fast RCNN, and Faster RCNN. Gandhi \citeyear{gandhi_2018} wrote in an article the comparism between the RCNN algorithms and YOLOv5. He said that the major drawbacks of RCNN is that it classifies 2000 regions per image everytime it runs, it cannot run in realtime and it is a fixed algorithm. Fast RCNN employs a similar algorithm to RCNN but instead of classifying regions everytime, it uses CNN to generate a convolutional feature map where the bounding regions are derived. Faster RCNN improves upon this by using a different network for predicting the regions of proposal. In his comparison he found that Fast RCNN improves on the speed of RCNN significantly. He also mentioned that Faster RCNN, the fastest of the RCNN algorithms, is viable for realtime object detection. 

\section{Vehicle Recognition/Identification Applications}
	
	In this study, Vehicle Recognition or Identification Applications would be considered as applications that either use any form of video-based software in locating the vehicle on the display feed, or software where static images can be used in identification. Chintalacheruvu and Muthukumar \citeyear{chintalacheruvu_2012} state that video based vehicle detection technology has features such as: “non-intrusiveness and comprehensive vehicle behavior data collection capabilities”, that it has become an integral part of f Intelligent Transportation System (ITS)

	V-App Vehicle Detection is a real-time vehicle detection system that utilizes the visual analytics provided by Meraki Smart Cameras and a License Plate Recognition function to ‘overcome the limitations of common sensors’. It also has features such as: vehicle distribution, which detects transit vehicles in an area by grouping them into categories; vehicle count and directions, which gets info on the total amount of vehicles transited and their direction details; and average busiest hours, which shows the higher transit and occupancy peaks in a graph. \cite{VAPP_ND}

	BitRefine Heads is a computer vision platform that “utilizes deep learning algorithms to perform high-level visual analysis” . It is a platform that detects everyday objects from any angle and also has a vehicle detection system. The recognition module is pre-trained and can detect vehicles as well as recognize the car’s model based on the visual features. It gets its video source from an Real Time Streaming Protocol (RTSP) stream from an IP-camera. The video then goes to a neural classifier that locates the vehicle in the frame and identifies its class using their own vehicle recognition module’s database.  The tracking module then takes the results and builds the vehicle’s movement track. Then it passes additional images of said vehicle to the neural module to check whether the class is correct. \cite{BITREFINE_ND}


\section{Vehicle Emission Calculator Applications}
	In this study, a vehicle emission calculator application would be regarded as applications that provide the total emission count or estimate of a vehicle after given inputs such as: a car’s make and model, car type, fuel type, and the like.
	
	The PM2.5 Footprint Calculator v1.01 is an online web browser tool by the constituents of Mahidol University, Thailand. It calculates the primary and secondary PM2.5 emissions (PM2.5, NOx, NH3, and SO2) by asking for the distance traveled, age of vehicle, fuel type, and city location. Due the calculator being “developed as a tool for enhancing environmentally sustainable passenger transport in Thailand,” it also displays information that assesses the health costs of health impacts of a vehicle. The effect of the emissions on humans’ health are calculated using  Disability-Adjusted Life Years (DALY) – which, according to the \cite{WHO_nd}, One DALY represents the loss of the equivalent of one year of full health. The calculator is divided into different vehicle types, each having their own dedicated page for calculating the PM2.5 levels. \cite{pm25_footprint}
	
	

	The Myclimate Car calculator is an online web browser application that determines the CO2 emissions of a car during its travel. The application asks for the distance traveled, along with the fuel type and fuel consumption. Users also have the option to enter the cart type (compact, mid-range, luxury/SUV/Van) to add to the calculation of the CO2 amount.  The basis of this calculation is through the utilization of the ecoinvent database (Version 3.6), using the IPCC 2013  (Intergovernmental Panel on Climate Change) evaluation method. The emissions are calculated per vehicle kilometer (vkm). The application creators further note that there is an uncertainty margin of 5\% added to the emissions due to statistical values used in the calculations. \cite{MCF_ND}

	The Next Greencar Make/Model Search Tool is an online car make and model search tool by Nextgreencar.com, a website established in 2007 in the purpose of helping car buyers transition from “fossil cars” to electric cars. This search tool takes the input of a car’s manufacturer and/or a specific model to provide results of : tail-pipe CO2, NOx, particulate emissions and the NGC Rating. NGC Rating or Next Green Car Rating is a rating developed by the company to assess the environmental impact. \cite{Lilly_ND}  The site then lists all the cars that satisfy the query, allowing users to compare them between their emissions. 

	The aforementioned applications use different techniques to calculate the harmful emissions from different vehicles but they commonly share the same process of asking for input: from the user via typing in the required information to output the estimated PM2.5, CO2, NOx, etc. emissions. Hazy, while utilizing the same process of using predetermined pollutant levels being assigned to a vehicle, relies on computer vision training instead of user input to determine the vehicle and estimate the amount of the pollutant they would emit.

\section{Summary}
 As the usage of vehicles in the Philippines rapidly increases through the years, it also starts becoming the main contributor to the air pollution in the country – a problem which the Philippines is still trying to mitigate. The studies mentioned above mention that in an attempt to solve this concern, emissions such as fine particulate matter ($PM_{2.5}$) from mobile vehicles are collected and analyzed through making applications that can keep track of the emissions by identifying the type of vehicle on screen.

	The type of vehicle can be identified through a collection of images of vehicles gathered by the researchers, being used for the model training of Hazy.  This can be utilized to create a system to identify vehicles via either still images and/or video. This chapter presented studies from different researchers that produced vehicle identification and recognition systems through machine learning and computer vision. Some of the applications used as an example can identify objects from a live video feed and produce results that list the vehicle type. Most of the related applications for vehicle tracking all use an in-house system that are  not publicly available to use without having to pay for them. The researchers instead utilized YOLOv5, an open source pre-trained algorithm that uses a system of grids to detect objects from images or videos to be used in the study.
	

	The recent studies make note of the interest in vehicle tracking systems and its benefits in managing traffic. This information, combined with the goal of reducing the emissions from vehicles that contribute to pollution, can be used to support the researchers’ purposes of the study.



